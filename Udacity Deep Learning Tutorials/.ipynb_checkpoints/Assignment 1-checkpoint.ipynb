{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hIbr52I7Z7U"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 1\n",
    "------------\n",
    "\n",
    "The objective of this assignment is to learn about simple data curation practices, and familiarize you with some of the data we'll be reusing later.\n",
    "\n",
    "This notebook uses the [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) dataset to be used with python experiments. This dataset is designed to look like the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, while looking a little more like real data: it's a harder task, and the data is a lot less 'clean' than MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "apJbCsBHl-2A"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from random import randint, sample\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNWGtZaXn-5j"
   },
   "source": [
    "First, we'll download the dataset to our local machine. The data consists of characters rendered in a variety of fonts on a 28x28 image. The labels are limited to 'A' through 'J' (10 classes). The training set has about 500k and the testset 19000 labeled examples. Given these sizes, it should be possible to train models quickly on any machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 186058,
     "status": "ok",
     "timestamp": 1444485672507,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2a0a5e044bb03b66",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "EYRJ4ICW6-da",
    "outputId": "0d0f85df-155f-4a89-8e7e-ee32df36ec8d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-db35b42b81cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdest_filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mtrain_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'notMNIST_large.tar.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m247336696\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mtest_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'notMNIST_small.tar.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8458043\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-db35b42b81cf>\u001b[0m in \u001b[0;36mmaybe_download\u001b[1;34m(filename, expected_bytes, force)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[1;34m\"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m   \u001b[0mdest_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempting to download:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "url = 'https://commondatastorage.googleapis.com/books1000/'\n",
    "last_percent_reported = None\n",
    "data_root = 'D:\\Domanis\\Datas' # Change me to store data elsewhere\n",
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  dest_filename = os.path.join(data_root, filename)\n",
    "  if force or not os.path.exists(dest_filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(dest_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', dest_filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "  return dest_filename\n",
    "\n",
    "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
    "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cC3p0oEyF8QT"
   },
   "source": [
    "Extract the dataset from the compressed .tar.gz file.\n",
    "This should give you a set of directories, labeled A through J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 186055,
     "status": "ok",
     "timestamp": 1444485672525,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2a0a5e044bb03b66",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "H8CBE-WZ8nmj",
    "outputId": "ef6c790c-2513-4b09-962e-27c79390c762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Domanis\\Datas\\notMNIST_large already present - Skipping extraction of D:\\Domanis\\Datas\\notMNIST_large.tar.gz.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Expected 10 folders, one per class. Found 11 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1c5b94bfe2ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata_folders\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtrain_folders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mtest_folders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1c5b94bfe2ac>\u001b[0m in \u001b[0;36mmaybe_extract\u001b[1;34m(filename, force)\u001b[0m\n\u001b[0;32m     19\u001b[0m     raise Exception(\n\u001b[0;32m     20\u001b[0m       'Expected %d folders, one per class. Found %d instead.' % (\n\u001b[1;32m---> 21\u001b[1;33m         num_classes, len(data_folders)))\n\u001b[0m\u001b[0;32m     22\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata_folders\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Expected 10 folders, one per class. Found 11 instead."
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4riXK3IoHgx6"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Let's take a peek at some of the data to make sure it looks sensible. Each exemplar should be an image of a character A through J rendered in a different font. Display a sample of the images that we just downloaded. Hint: you can use the package IPython.display.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACNklEQVR4nG2S30uTcRTGn3O+75vOZO9+qEPn1Ba+MotqaRdSSHQRFKEW3RQEgf0FhjddeNff0EUE3URddJVRKEZBA9soZFMEc7qVPzDcYramze39frtY0zfr3D18znk4PDwE25By99eN/yT1R2t2yNZIwAjeZ+s/kC1zbZ1+dS2wxL9jXKkZGMI17962HZ6KFLMN2lRPVe/bkjKHc6U3fNdo2YpWjPchW4NNt/ApP3g5cjN6wJYsv89EIbG6EA81mZL/hjDbDMzNzYtFt7sPdOChXpen8BzZr8tc3wNphyRbWoPF3CQwvbPU3nxSsQ0ywoZ/N5Zgiv2IteIsyAalMIPa1iSYy/MraO7WJREYJASBVKCrwVp/BamQTqUaPWFFCgxlWYprMFgbSie3fYbh3elImt7req2ukavhaDFft3mnf/PirDt1SOqHXZnptsdXsx0nPmr+gYHXzzbWnBuduZIzUKsLcs4kMi886OsoEoA6l9s9+v12xPGoxEJ3uGAK0qykMw1iBkGMTZTfD1eSFrj3UL186gGxkpIYofqe5LcJSGJmwtT2fDjTCcEAlEKXz7kZXyWppJRlxDOpFiOESvpShAO8PltNRBSXVtB9ySErEYbad2P6DKqtw1JrJH2kDxoAhbYPX8zjmSq0KJqfifgC0ABSvvBEwZEs7JWO1BNHKjfk1AC2zh/L0Lkxe9VSI+Q3ezUAOH3jwvaD5f22KiwWRw1zjgGJz+8KjeO2OyVK0TPq7cpvBE7UCSbhKGkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "liste = os.listdir(\"D:/Domanis/Datas/notMNIST_large/A\")\n",
    "num = randint(0,len(liste))\n",
    "#image = Image(\"D:/Domanis/Datas/notMNIST_large/A/{Image}\".format(Image=liste[num]))\n",
    "image = Image(os.path.join(\"D:/Domanis/Datas/notMNIST_large/A\",liste[num]))\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBdkjESPK8tw"
   },
   "source": [
    "Now let's load the data in a more manageable format. Since, depending on your computer setup you might not be able to fit it all in memory, we'll load each class into a separate dataset, store them on disk and curate them independently. Later we'll merge them into a single dataset of manageable size.\n",
    "\n",
    "We'll convert the entire dataset into a 3D array (image index, x, y) of floating point values, normalized to have approximately zero mean and standard deviation ~0.5 to make training easier down the road. \n",
    "\n",
    "A few images might not be readable, we'll just skip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 30
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 399874,
     "status": "ok",
     "timestamp": 1444485886378,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2a0a5e044bb03b66",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "h7q0XhG3MJdf",
    "outputId": "92c391bb-86ff-431d-9ada-315568a19e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling D:/Domanis/Datas/notMNIST_large\\A.pickle.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f5f86051d842>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdataset_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mtrain_datasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/Domanis/Datas/notMNIST_large\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m45000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[0mtest_datasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/Domanis/Datas/notMNIST_small\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1800\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-f5f86051d842>\u001b[0m in \u001b[0;36mmaybe_pickle\u001b[1;34m(path, min_num_images_per_class, force)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m       \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pickling %s.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mset_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m       \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_letter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_num_images_per_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-f5f86051d842>\u001b[0m in \u001b[0;36mload_letter\u001b[1;34m(folder, min_num_images)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_letter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_num_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;34m\"\"\"Load the data for a single letter label.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0mimage_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m   dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n\u001b[0;32m      8\u001b[0m                          dtype=np.float32)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single letter label.\"\"\"\n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "  print(folder)\n",
    "  num_images = 0\n",
    "  for image in image_files:\n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      image_data = (imageio.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      num_images = num_images + 1\n",
    "    except (IOError, ValueError) as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset\n",
    "        \n",
    "def maybe_pickle(path, min_num_images_per_class, force=False):\n",
    "  dataset_names = []\n",
    "  data_folders = os.listdir(path)\n",
    "  for folder in data_folders:\n",
    "    full_path = os.path.join(path,folder)\n",
    "    set_filename = full_path + '.pickle'\n",
    "    dataset_names.append(set_filename)\n",
    "    if os.path.exists(set_filename) and not force:\n",
    "      # You may override by setting force=True.\n",
    "      print('%s already present - Skipping pickling.' % set_filename)\n",
    "    else:\n",
    "      print('Pickling %s.' % set_filename)\n",
    "      dataset = load_letter(full_path, min_num_images_per_class)\n",
    "      try:\n",
    "        with open(set_filename, 'wb') as f:\n",
    "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "      except Exception as e:\n",
    "        print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "  return dataset_names\n",
    "train_datasets = maybe_pickle(\"D:/Domanis/Datas/notMNIST_large\", 45000)\n",
    "test_datasets = maybe_pickle(\"D:/Domanis/Datas/notMNIST_small\", 1800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUdbskYE2d87"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "Let's verify that the data still looks good. Displaying a sample of the labels and images from the ndarray. Hint: you can use matplotlib.pyplot.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2163716b7b8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEsJJREFUeJzt3X+M1PWZB/D3M7Ozu+wPBUWQ8kNQacXTHF622NQLsefRoy1X8C4aOU9pz5PmFH8kpneEayJ/XBvanFbbXLzguQeYVu2l/iCVWAlt5KzGsiARFCwW1wVBfq78WoGdmef+2Fluxf0+n2G+M/Od3ef9Sgi788x357Oz+97vzj7fz+cjqgoi8ieV9ACIKBkMP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RU3XVfLB6adBGNFfzISng1CT76zHpvINm/eNck1k/nY/+Fsvm7XNPNhs4N+XEruej63Wf2IemD52w71CjTuIETuupwBPTJ1b4RWQ2gEcBpAH8l6ous+7fiGZcKzfEeUgajBhf68Dl2zsWX2vWH/2rFWZ9dfc1Zr3rxKjI2sEe+wfPoY9bzHr2SL1ZTx9PR9YufMs8FCOffN2+g/WcA8HnvVLe0HVF37fkX/tFJA3gPwB8DcCVAOaLyJWlfjwiqq44r/lnAHhPVXeq6mkATwOYW55hEVGlxQn/eAC7Bry/u3Dbp4jIQhHpEJGOXpyK8XBEVE5xwj/Yi57PvNBR1eWq2qaqbRk0xHg4IiqnOOHfDWDigPcnANgTbzhEVC1xwr8BwFQRmSIi9QBuAbC6PMMiokorudWnqlkRWQTg1+hr9bWr6ttlGxn9vxhtpfSVnzcPXTfnIbM+JWO322aNeM2spyX6/HI8f9I8tiXVaNZ7NWfWMxLd6rvr+i+Zx/7xSbMMGJ8XACAwtloQq8+vqmsArCnTWIioinh5L5FTDD+RUww/kVMMP5FTDD+RUww/kVNVnc9PpZG6jFnX3tORte3/3GoeG+rjH8nbE9/PT40w6zO33BhZ+6jbHtsfZq4y68fz9lyRUenotQZa6+xrDDzgmZ/IKYafyCmGn8gphp/IKYafyCmGn8gptvpqQSp66ilgt/IAQL54dWRtxcwnShpSvxaxV186mLOXuG74wcjImsyyp+xipl3OhKbVGibUd5v1zYhedXi44JmfyCmGn8gphp/IKYafyCmGn8gphp/IKYafyCn2+YeBd78dPa12ZqCV3p3rMevWtFgAmLHuXrM+9ZWNkbW6L3/ZPLaSzk+HtuAO9Pk1X7axJIVnfiKnGH4ipxh+IqcYfiKnGH4ipxh+IqcYfiKnYvX5RaQTwDEAOQBZVW0rx6CGndAW23l7O+f01EvN+pqvP2JU7T59qI//Yo99ocC0pQfMetaotXYl1ytvTgXWSGiw1zHQU/ay4XG2Va+Wclzk8xVVPViGj0NEVcRf+4mciht+BfCyiGwUkYXlGBARVUfcX/uvU9U9IjIGwFoR2a6q6wfeofBDYSEANAZefxJR9cQ686vqnsL/+wE8B2DGIPdZrqptqtqWgf1HFCKqnpLDLyLNItLa/zaArwLYWq6BEVFlxfm1fyyA56SvpVEH4Oeq+lJZRkVEFVdy+FV1J4A/LeNYhi1JB9blz1rdcGDbA6PN+rT66L+l9OTtfnZTqt6sL/7PfzDrn+t8zaxbRhy0P++QVIxXrc0pu0+farW3Ls+F+vxDAFt9RE4x/EROMfxETjH8RE4x/EROMfxETnHp7nIIbbEdaOWlrrrCrD/2lyvPeUj9Qq282z+w98Ee/8jv7Qeos7+FrM+9vttul3Vlj5v1SXV2O87SKL1mXVqa7Q9w8FDJj10reOYncorhJ3KK4SdyiuEncorhJ3KK4SdyiuEncop9/jKQlL1Mc2g353fvHGnWZzfZ/fDQtF3LB9+3rzFozNp9fsnY1xFY0h/b24NvOPk5sz6p5WjJj90UmNKrzdHbnhdFAudVtZdrrwae+YmcYviJnGL4iZxi+ImcYviJnGL4iZxi+ImcYp+/WMaWy6H5+nVTLjHrT3/zp4EHz5hVa87+pWvtpben/iowXz+4VoE9L97UbffpN56YbNb/tuWtkh+6WeyvWb6p9OsXhgqe+YmcYviJnGL4iZxi+ImcYviJnGL4iZxi+ImcCvb5RaQdwBwA+1X1qsJtFwB4BsBkAJ0AblbV7soNM3nWNtuhPv/2+8aZ9RkNdh8/5PkT0evXX/FDe+37JGeV5w4dNutbj9rz+TG29D5/k9ifebbF/prYVz8MDcWc+VcAmH3WbYsBrFPVqQDWFd4noiEkGH5VXQ/g7B/RcwH0byOzEsC8Mo+LiCqs1Nf8Y1V1LwAU/h9TviERUTVU/Np+EVkIYCEANKKp0g9HREUq9cy/T0TGAUDh//1Rd1TV5arapqptGTSU+HBEVG6lhn81gAWFtxcAeKE8wyGiagmGX0SeAvA6gC+IyG4RuQPAMgCzRGQHgFmF94loCAm+5lfV+RGlG8o8lmQZ8/UBu5cfmq//kzkrShlR0ZasuD2yNvGd18xjQ+vua2/pewIAgNRFf4uFro/o7B4V67F7jbXxG+0vN7JNdic/1OePu5dDNfAKPyKnGH4ipxh+IqcYfiKnGH4ipxh+Iqe4dHeB1NlTOK2W17t32VNPv9F0sqQx9bt3zxfN+qQfGstvG602AMGek9WqK4Y0RF/VGWr1HeuOdzl4HtGfW1NgSfLeJvu8OByuVeWZn8gphp/IKYafyCmGn8gphp/IKYafyCmGn8gpP33+0JTdwNRVa9ruw/NWRtaKcTB3wqy/892rzXo6uym6GOhnI1/hxbul9PNLZm+8bbJTxrmtUexv/eyI4X9eHP6fIRENiuEncorhJ3KK4SdyiuEncorhJ3KK4SdyylGfP/BzzljmGQB2LIyes//N5p5SRnTGoq6/NusaWAb65JwZkTXJq/3ggXLoeAl9eGPoDYfsdQ5yTYEPHpBC9INnxF6/ITsi1kPHur6hWmp/hERUEQw/kVMMP5FTDD+RUww/kVMMP5FTDD+RU8E+v4i0A5gDYL+qXlW4bSmAOwEcKNxtiaquqdQgixKYrx+at1437mKz/pOb2s91RGccz9v97JWTf23W61YFtoseAj3lSshVcJ/r7IjA99MwUMx3zQoAswe5/ceqOr3wL9ngE9E5C4ZfVdcDOFyFsRBRFcX5fXGRiLwlIu0iMqpsIyKiqig1/I8BuAzAdAB7ATwUdUcRWSgiHSLS0YtTJT4cEZVbSeFX1X2qmlPVPIDHAUTOLFHV5arapqptmWGxvSHR8FBS+EVk3IB3bwSwtTzDIaJqKabV9xSA6wGMFpHdAB4EcL2ITEffhNBOAN+p4BiJqAKC4VfV+YPc/EQFxhKL1Nnzs0Pr8u+4Z4pZn930UmTtlPaax7akGs16XL3GWgRHAtcY9Kg9Z/5Y3r7GoDNr/6238/RFkbVtJ6LXSACAupR9bca/jX3VrI+Q0tf9jz2ffwjweXUIETH8RF4x/EROMfxETjH8RE4x/ERODa2lu43tpoNbbE+eZNbvm/erkoYEAPd+ONOsb2ifbtbr7G4cGo7aU1frj2Qja5kj9iXV6cPHzboeOWrXP7EHr73RY9PewNgut9uv76y125AzGko/t+XidmcDy63XAp75iZxi+ImcYviJnGL4iZxi+ImcYviJnGL4iZwaWn3+GN7/+wlm/e6Rq816Vza6H77tB1ebx170/OtmXersL4Nmo3vlIaFNrkv/yJWX79xl1g/kWgMfIXABhSHXEG978KGAZ34ipxh+IqcYfiKnGH4ipxh+IqcYfiKnGH4ip2qrzx9jm+30KHsJ6X+97ZlSRnTGV165J7J2+fO/N49NNdqTw0N9/OB1APkYPekKbnMdFNhaPPS8vNkz2ax/o2n7uY7ojFxTgs9LlfDMT+QUw0/kFMNP5BTDT+QUw0/kFMNP5BTDT+RUsM8vIhMBrAJwMYA8gOWq+qiIXADgGQCTAXQCuFlVu+MMJs422+/fN8089tbW35r1l3oazPoVD0Z/aqE58flT9vr0CGyTPXzF66W/cmCqWf/e6NL7/NrAPj/Q9739gKpOA/AlAHeLyJUAFgNYp6pTAawrvE9EQ0Qw/Kq6V1U3Fd4+BmAbgPEA5gJYWbjbSgDzKjVIIiq/c3rNLyKTAVwD4A0AY1V1L9D3AwLAmHIPjogqp+jwi0gLgF8CuF9V7Q3cPn3cQhHpEJGOXgRe+xJR1RQVfhHJoC/4P1PVZws37xORcYX6OAD7BztWVZerapuqtmVg/1GNiKonGH4REQBPANimqg8PKK0GsKDw9gIAL5R/eERUKcVM6b0OwG0AtojI5sJtSwAsA/ALEbkDQBeAm4p6xDjbbE8YH1m79W9+U9TDR3mg/Q6zPmHna5E1ydSbx4Y+L7cCU3qh0VO4AWDn3tH28Xb31ySN9mMHxZlmXSXB8KvqqwCiJtrfUN7hEFG18Ao/IqcYfiKnGH4ipxh+IqcYfiKnGH4ip2pr6e6Arr+7JLL24ugXzWMXfXitWZ/40EazbnVtNdtrHkuVkdptL4keR6axwpuXG9e7SMpewl5zxjUI53B5Ac/8RE4x/EROMfxETjH8RE4x/EROMfxETjH8RE5Vv89vbLOdamoyD73/28+adcubP5pu1ltOvWF/AKMva31OVDnNewJbusfQ0BDv2g2zFw+YW6NrtjprAfDMT+QUw0/kFMNP5BTDT+QUw0/kFMNP5BTDT+RUTc3n33WP3Yu/4/zotfOn/e4289hJ/xOjjw+wl1+Dzuuq3Jz78xrtreVSra12/aILzXpuVHNkrWdCdA0AWjftiazJR/Y29wPxzE/kFMNP5BTDT+QUw0/kFMNP5BTDT+QUw0/kVLDPLyITAawCcDGAPIDlqvqoiCwFcCeAA4W7LlHVNebHqksjPfKCyPott/7GHEtX9nhk7ZJl0fOjgXNazpyGiMb9di/ekjPm0wNA+7Qnzfr2TReZ9b8YcdisZyT6upIGsXv1bQ/+U2St99l689iBirnIJwvgAVXdJCKtADaKyNpC7ceq+u9FPxoR1Yxg+FV1L4C9hbePicg2AOMrPTAiqqxzes0vIpMBXAOg/1rZRSLyloi0i8ioiGMWikiHiHSczp+MNVgiKp+iwy8iLQB+CeB+VT0K4DEAlwGYjr7fDB4a7DhVXa6qbaraVp+q3N5qRHRuigq/iGTQF/yfqeqzAKCq+1Q1p6p5AI8DmFG5YRJRuQXDLyIC4AkA21T14QG3jxtwtxsBbC3/8IioUor5a/91AG4DsEVENhduWwJgvohMR18XrRPAd0If6PSFjdh1+xWR9e+Ntlt9X/jv70bWJm983TxW6uxPVbMV3pKZyi591G71vX36k8jan9SPMI/9fMaeVntS7Vbet96fY9bf3HB5ZG38ersNOeaV7ZG1Px4p/u9qxfy1/1UAgy2Qbvb0iai28Qo/IqcYfiKnGH4ipxh+IqcYfiKnGH4ip6q6dHf9x1lMXL0vsn613GUef9njb0fWQgtrs49fgwLTakNS3UfN+s0b/zGy1nPQ3g5+/Mv2efH833Wa9exH0d/nAHA5Dpp1i/W9rlr8EvM88xM5xfATOcXwEznF8BM5xfATOcXwEznF8BM5JarVW9RaRA4A+GDATaOBGA3PyqrVsdXquACOrVTlHNslqmqvK15Q1fB/5sFFOlS1LbEBGGp1bLU6LoBjK1VSY+Ov/UROMfxETiUd/uUJP76lVsdWq+MCOLZSJTK2RF/zE1Fykj7zE1FCEgm/iMwWkXdF5D0RWZzEGKKISKeIbBGRzSLSkfBY2kVkv4hsHXDbBSKyVkR2FP4fdJu0hMa2VEQ+LDx3m0Xk6wmNbaKI/FZEtonI2yJyX+H2RJ87Y1yJPG9V/7VfRNIA/gBgFoDdADYAmK+q71R1IBFEpBNAm6om3hMWkZkAjgNYpapXFW77EYDDqrqs8INzlKr+S42MbSmA40nv3FzYUGbcwJ2lAcwD8C0k+NwZ47oZCTxvSZz5ZwB4T1V3quppAE8DmJvAOGqeqq4HcPbuEHMBrCy8vRJ93zxVFzG2mqCqe1V1U+HtYwD6d5ZO9LkzxpWIJMI/HsCuAe/vRm1t+a0AXhaRjSKyMOnBDGJsYdv0/u3TxyQ8nrMFd26uprN2lq6Z566UHa/LLYnwD7b7Ty21HK5T1T8D8DUAdxd+vaXiFLVzc7UMsrN0TSh1x+tySyL8uwFMHPD+BAB7EhjHoFR1T+H//QCeQ+3tPryvf5PUwv/7Ex7PGbW0c/NgO0ujBp67WtrxOonwbwAwVUSmiEg9gFsArE5gHJ8hIs2FP8RARJoBfBW1t/vwagALCm8vAPBCgmP5lFrZuTlqZ2kk/NzV2o7XiVzkU2hlPAIgDaBdVb9f9UEMQkQuRd/ZHuhb2fjnSY5NRJ4CcD36Zn3tA/AggOcB/ALAJABdAG5SDWwZW72xXY++X13P7Nzc/xq7ymP7cwD/C2ALgP4lgpeg7/V1Ys+dMa75SOB54xV+RE7xCj8ipxh+IqcYfiKnGH4ipxh+IqcYfiKnGH4ipxh+Iqf+D+C1N+1/vwGwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x216371db9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_pickles(chemin):\n",
    "  with open(chemin,'rb') as f:\n",
    "    return pickle.load(f)\n",
    "\n",
    "A = load_pickles('D:/Domanis/Datas/notMNIST_large/pickle/A.pickle')\n",
    "plt.imshow(A[randint(0,len(A))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYznx5jUwzoO"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Another check: we expect the data to be balanced across classes. Verify that.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.2909e+04 -2.4000e+00]\n",
      " [ 5.2911e+04 -4.0000e-01]\n",
      " [ 5.2912e+04  6.0000e-01]\n",
      " [ 5.2911e+04 -4.0000e-01]\n",
      " [ 5.2912e+04  6.0000e-01]\n",
      " [ 5.2912e+04  6.0000e-01]\n",
      " [ 5.2912e+04  6.0000e-01]\n",
      " [ 5.2912e+04  6.0000e-01]\n",
      " [ 5.2912e+04  6.0000e-01]\n",
      " [ 5.2911e+04 -4.0000e-01]]\n"
     ]
    }
   ],
   "source": [
    "A = load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')\n",
    "B = load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')\n",
    "C = load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')\n",
    "D = load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')\n",
    "E = load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')\n",
    "F = load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')\n",
    "G = load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')\n",
    "H = load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')\n",
    "I = load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')\n",
    "J = load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle')\n",
    "l = np.array([len(A),len(B),len(C),len(D),len(E),len(F),len(G),len(H),len(I),len(J)]).reshape((10,1))\n",
    "m = sum(l)/10\n",
    "d = np.array([len(A)-m,len(B)-m,len(C)-m,len(D)-m,len(E)-m,len(F)-m,len(G)-m,len(H)-m,len(I)-m,len(J)-m]).reshape((10,1))\n",
    "print(np.hstack((l,d)))\n",
    "del A,B,C,D,E,F,G,H,I,J,l,m,d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'approche dite du \"suicide mental\" (les lignes précédentes condensées en une seule):\n",
    "------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.29090000e+04  -2.40000000e+00]\n",
      " [  5.29110000e+04  -4.00000000e-01]\n",
      " [  5.29120000e+04   6.00000000e-01]\n",
      " [  5.29110000e+04  -4.00000000e-01]\n",
      " [  5.29120000e+04   6.00000000e-01]\n",
      " [  5.29120000e+04   6.00000000e-01]\n",
      " [  5.29120000e+04   6.00000000e-01]\n",
      " [  5.29120000e+04   6.00000000e-01]\n",
      " [  5.29120000e+04   6.00000000e-01]\n",
      " [  5.29110000e+04  -4.00000000e-01]]\n"
     ]
    }
   ],
   "source": [
    "#print(np.hstack((np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)),np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle'))-sum(np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)))/10,len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle'))-sum(np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)))/10,len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle'))-sum(np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)))/10,len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle'))-sum(np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)))/10,len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle'))-sum(np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)))/10,len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle'))-sum(np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)))/10,len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle'))-sum(np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)))/10,len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle'))-sum(np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)))/10,len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle'))-sum(np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)))/10,len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))-sum(np.array([len(load_pickles('D:/Domanis/Datas/notMNIST_large/A.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/B.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/C.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/D.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/E.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/F.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/G.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/H.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/I.pickle')),len(load_pickles('D:/Domanis/Datas/notMNIST_large/J.pickle'))]).reshape((10,1)))/10]).reshape((10,1)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LA7M7K22ynCt"
   },
   "source": [
    "Merge and prune the training data as needed. Depending on your computer setup, you might not be able to fit it all in memory, and you can tune `train_size` as needed. The labels will be stored into a separate array of integers 0 through 9.\n",
    "\n",
    "Also create a validation dataset for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 411281,
     "status": "ok",
     "timestamp": 1444485897869,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2a0a5e044bb03b66",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "s3mWgZLpyuzq",
    "outputId": "8af66da6-902d-4719-bedc-7c9fb7ae7948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (200000, 28, 28) (200000,)\n",
      "Validation: (10000, 28, 28) (10000,)\n",
      "Testing: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def make_arrays(nb_rows, img_size):\n",
    "  if nb_rows:\n",
    "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "  else:\n",
    "    dataset, labels = None, None\n",
    "  return dataset, labels\n",
    "\n",
    "def merge_datasets(chemin, train_size, valid_size=0):\n",
    "  pickle_files = os.listdir(chemin)  \n",
    "  num_classes = len(pickle_files)\n",
    "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "  vsize_per_class = valid_size // num_classes\n",
    "  tsize_per_class = train_size // num_classes\n",
    "    \n",
    "  start_v, start_t = 0, 0\n",
    "  end_v, end_t = vsize_per_class, tsize_per_class\n",
    "  end_l = vsize_per_class+tsize_per_class\n",
    "  for label, pickle_file in enumerate(pickle_files):\n",
    "    chemin_full = os.path.join(chemin,pickle_file)\n",
    "    try:\n",
    "      with open(chemin_full, 'rb') as f:\n",
    "        letter_set = pickle.load(f)\n",
    "        # let's shuffle the letters to have random validation and training set\n",
    "        np.random.shuffle(letter_set)\n",
    "        if valid_dataset is not None:\n",
    "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "          valid_labels[start_v:end_v] = label\n",
    "          start_v += vsize_per_class\n",
    "          end_v += vsize_per_class\n",
    "                    \n",
    "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "        train_dataset[start_t:end_t, :, :] = train_letter\n",
    "        train_labels[start_t:end_t] = label\n",
    "        start_t += tsize_per_class\n",
    "        end_t += tsize_per_class\n",
    "    except Exception as e:\n",
    "      print('Unable to process data from', pickle_file, ':', e)\n",
    "      raise\n",
    "    \n",
    "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "test_size = 10000\n",
    "\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets('D:\\\\Domanis\\\\Datas\\\\notMNIST_large\\\\pickle', train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets('D:\\\\Domanis\\\\Datas\\\\notMNIST_small\\\\pickle', test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPTCnjIcyuKN"
   },
   "source": [
    "Next, we'll randomize the data. It's important to have the labels well shuffled for the training and test distributions to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6WZ2l2tN2zOL"
   },
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puDUTe6t6USl"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "Convince yourself that the data is still good after shuffling!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label de l'image: G\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x216413a4b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = randint(0,len(train_dataset))\n",
    "plt.imshow(train_dataset[num])\n",
    "labels = ['A','B','C','D','E','F','G','H','I','J']\n",
    "print(\"Label de l'image: \" + labels[train_labels[num]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tIQJaJuwg5Hw"
   },
   "source": [
    "Finally, let's save the data for later reuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QiR_rETzem6C"
   },
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 413065,
     "status": "ok",
     "timestamp": 1444485899688,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2a0a5e044bb03b66",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "hQbLjrW_iT39",
    "outputId": "b440efc6-5ee1-4cbc-d02d-93db44ebd956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 690800506\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gE_cRAQB33lk"
   },
   "source": [
    "---\n",
    "Problem 5\n",
    "---------\n",
    "\n",
    "By construction, this dataset might contain a lot of overlapping samples, including training data that's also contained in the validation and test set! Overlap between training and test can skew the results if you expect to use your model in an environment where there is never an overlap, but are actually ok if you expect to see training samples recur when you use it.\n",
    "Measure how much overlap there is between training, validation and test samples.\n",
    "\n",
    "Optional questions:\n",
    "- What about near duplicates between datasets? (images that are almost identical)\n",
    "- Create a sanitized validation and test set, and compare your accuracy on those in subsequent assignments.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution extrêmement non optimisée\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images de l'échantillon présentes dans valid_dataset: 0\n",
      "Nombre d'images de l'échantillon présentes dans test_dataset: 0\n"
     ]
    }
   ],
   "source": [
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "with open(pickle_file,'rb') as f:\n",
    "    datas = pickle.load(f)\n",
    "train_dataset = datas['train_dataset']\n",
    "train_labels = datas['train_labels']\n",
    "valid_dataset = datas['valid_dataset']\n",
    "valid_labels = datas['valid_labels']\n",
    "test_dataset = datas['test_dataset']\n",
    "test_labels = datas['test_labels']\n",
    "compteur_valid = 0\n",
    "compteur_test = 0\n",
    "\n",
    "sample_size = 10\n",
    "num = randint(0,len(train_dataset)-sample_size)\n",
    "\n",
    "for train_image in train_dataset[num:num+sample_size]:\n",
    "  for valid_image in valid_dataset:\n",
    "    if np.all([train_image,valid_image]) is True:\n",
    "      compteur_valid += 1\n",
    "\n",
    "for train_image in train_dataset[num:num+sample_size]:\n",
    "  for test_image in test_dataset:\n",
    "    if np.all([train_image,test_image]) is True:\n",
    "      compteur_test +=1\n",
    "print(\"Nombre d'images de l'échantillon présentes dans valid_dataset: \" + str(compteur_valid))\n",
    "print(\"Nombre d'images de l'échantillon présentes dans test_dataset: \" + str(compteur_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impossible de lire D:\\Domanis\\Datas/notMNIST_large\\A\\RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png\n",
      "Impossible de lire D:\\Domanis\\Datas/notMNIST_large\\A\\SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png\n",
      "Impossible de lire D:\\Domanis\\Datas/notMNIST_large\\A\\Um9tYW5hIEJvbGQucGZi.png\n",
      "Impossible de lire D:\\Domanis\\Datas/notMNIST_large\\B\\TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-16ff261674f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mHash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mnom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchemin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchemin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0ms_hash\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mHash\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms_hash\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHash\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnom\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Impossible de lire '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mchemin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Domanis\\Anaconda\\lib\\shelve.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeyencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Domanis\\Anaconda\\lib\\dbm\\dumb.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modified\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_addkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_addval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[1;31m# See whether the new value is small enough to fit in the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Domanis\\Anaconda\\lib\\dbm\\dumb.py\u001b[0m in \u001b[0;36m_addval\u001b[1;34m(self, val)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;31m#     (starting offset of val, len(val))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_addval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0m_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import PIL as p\n",
    "from glob import glob\n",
    "import shelve\n",
    "from imagehash import dhash\n",
    "\n",
    "s_hash = shelve.open(data_root +'/large_hash_shelve', writeback=True)\n",
    "for chemin in glob(data_root+'/notMNIST_large/*/*.png'):\n",
    "    try:\n",
    "        image = p.Image.open(chemin)\n",
    "        Hash = str(dhash(image))\n",
    "        nom = chemin[chemin.rfind('/')+1:]\n",
    "        s_hash[Hash] = s_hash.get(Hash,[]) + [chemin]\n",
    "    except Exception:\n",
    "        print('Impossible de lire '+chemin)\n",
    "s_hash.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8oww1s4JMQx"
   },
   "source": [
    "---\n",
    "Problem 6\n",
    "---------\n",
    "\n",
    "Let's get an idea of what an off-the-shelf classifier can give you on this data. It's always good to check that there is something to learn, and that it's a problem that is not so trivial that a canned solution solves it.\n",
    "\n",
    "Train a simple model on this data using 50, 100, 1000 and 5000 training samples. Hint: you can use the LogisticRegression model from sklearn.linear_model.\n",
    "\n",
    "Optional question: train an off-the-shelf model on all the data!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=42, solver='lbfgs',\n",
       "          tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _3dto2d(x):\n",
    "    if len(x.shape) == 3:\n",
    "        x = np.reshape(x,(x.shape[0],x.shape[1]*x.shape[2]))\n",
    "    return x\n",
    "\n",
    "sample = 1000\n",
    "train_dataset = _3dto2d(train_dataset)\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42, verbose=1, max_iter=1000)\n",
    "model.fit(train_dataset[:sample],train_labels[:sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78152"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_dataset,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = _3dto2d(test_dataset)\n",
    "model.score(test_dataset,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7759"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = _3dto2d(valid_dataset)\n",
    "model.score(valid_dataset,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "1_notmnist.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
